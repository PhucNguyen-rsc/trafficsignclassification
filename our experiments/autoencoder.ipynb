{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["# import libraries\r\n","from IPython.display import Image, display\r\n","import numpy as np\r\n","import os\r\n","from os.path import join\r\n","from PIL import ImageFile\r\n","import pandas as pd\r\n","from matplotlib import cm\r\n","import seaborn as sns\r\n","from tensorflow.python.keras.models import Sequential\r\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\r\n","import matplotlib.pyplot as plt\r\n","from sklearn.utils import shuffle\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.preprocessing import StandardScaler\r\n","from sklearn.decomposition import PCA\r\n","from sklearn.ensemble import IsolationForest\r\n","from sklearn.covariance import EllipticEnvelope\r\n","from sklearn import svm\r\n","from sklearn.mixture import GaussianMixture\r\n","from sklearn.isotonic import IsotonicRegression\r\n","import re\r\n","from tqdm import tqdm\r\n","import cv2\r\n","import pickle\r\n","import tensorflow as tf\r\n","from tensorflow.keras.applications import *\r\n","from tensorflow.keras.layers import *\r\n","from tensorflow.keras import *\r\n","from tensorflow.keras.models import *\r\n","import tensorflow as tf\r\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n","plt.style.use('fivethirtyeight')\r\n","%matplotlib inline\r\n","from tensorflow.keras.callbacks import EarlyStopping\r\n","from keras.preprocessing import image\r\n","import glob\r\n","\r\n","import warnings;\r\n","warnings.filterwarnings('ignore')"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-10T14:00:29.614456Z","iopub.execute_input":"2021-08-10T14:00:29.614847Z","iopub.status.idle":"2021-08-10T14:00:34.982852Z","shell.execute_reply.started":"2021-08-10T14:00:29.614755Z","shell.execute_reply":"2021-08-10T14:00:34.982028Z"},"trusted":true}},{"cell_type":"markdown","source":["# Auto Encoder"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# download dataset\r\n","! wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\r\n","# extract dataset\r\n","! tar -xvzf lfw.tgz"],"outputs":[],"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"scrolled":true,"execution":{"iopub.status.busy":"2021-08-06T11:29:03.537094Z","iopub.execute_input":"2021-08-06T11:29:03.537464Z","iopub.status.idle":"2021-08-06T11:29:09.411657Z","shell.execute_reply.started":"2021-08-06T11:29:03.537431Z","shell.execute_reply":"2021-08-06T11:29:09.410532Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#capture paths to images\r\n","face_images = glob.glob('lfw/**/*.jpg')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-06T11:29:14.613567Z","iopub.execute_input":"2021-08-06T11:29:14.613915Z","iopub.status.idle":"2021-08-06T11:29:14.78144Z","shell.execute_reply.started":"2021-08-06T11:29:14.613879Z","shell.execute_reply":"2021-08-06T11:29:14.780582Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["all_images = []\r\n","\r\n","for i in tqdm(face_images):\r\n","  img = image.load_img(i, target_size = (75, 75, 3))\r\n","  img = image.img_to_array(img)\r\n","  img = img/255.0\r\n","  all_images.append(img)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-06T11:29:24.682403Z","iopub.execute_input":"2021-08-06T11:29:24.682755Z","iopub.status.idle":"2021-08-06T11:29:42.401633Z","shell.execute_reply.started":"2021-08-06T11:29:24.682722Z","shell.execute_reply":"2021-08-06T11:29:42.40066Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["all_images = np.array(all_images)\r\n","\r\n","# split data into train and validation data\r\n","train_x, val_x = train_test_split(all_images, random_state = 42, test_size = 0.1)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:03.062167Z","iopub.execute_input":"2021-08-03T06:17:03.062662Z","iopub.status.idle":"2021-08-03T06:17:03.779683Z","shell.execute_reply.started":"2021-08-03T06:17:03.062614Z","shell.execute_reply":"2021-08-03T06:17:03.778241Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def pixalate_image(image, scale_percent = 40):\r\n","  width = int(image.shape[1] * scale_percent / 100)\r\n","  height = int(image.shape[0] * scale_percent / 100)\r\n","  dim = (width, height)\r\n","\r\n","  small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\r\n","  \r\n","  # scale back to original size\r\n","  width = int(small_image.shape[1] * 100 / scale_percent)\r\n","  height = int(small_image.shape[0] * 100 / scale_percent)\r\n","  dim = (width, height)\r\n","\r\n","  low_res_image = cv2.resize(small_image, dim, interpolation = cv2.INTER_AREA)\r\n","\r\n","  return low_res_image"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:03.784191Z","iopub.execute_input":"2021-08-03T06:17:03.787962Z","iopub.status.idle":"2021-08-03T06:17:03.799654Z","shell.execute_reply.started":"2021-08-03T06:17:03.787908Z","shell.execute_reply":"2021-08-03T06:17:03.798626Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# get low resolution images for the training set\r\n","train_x_px = []\r\n","\r\n","for i in range(train_x.shape[0]):\r\n","  temp = pixalate_image(train_x[i,:,:,:])\r\n","  train_x_px.append(temp)\r\n","\r\n","train_x_px = np.array(train_x_px)\r\n","\r\n","\r\n","# get low resolution images for the validation set\r\n","val_x_px = []\r\n","\r\n","for i in range(val_x.shape[0]):\r\n","  temp = pixalate_image(val_x[i,:,:,:])\r\n","  val_x_px.append(temp)\r\n","\r\n","val_x_px = np.array(val_x_px)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:03.801209Z","iopub.execute_input":"2021-08-03T06:17:03.801993Z","iopub.status.idle":"2021-08-03T06:17:05.111183Z","shell.execute_reply.started":"2021-08-03T06:17:03.801947Z","shell.execute_reply":"2021-08-03T06:17:05.11001Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# get low resolution images for the training set\r\n","train_x_px = []\r\n","\r\n","for i in range(train_x.shape[0]):\r\n","  temp = pixalate_image(train_x[i,:,:,:])\r\n","  train_x_px.append(temp)\r\n","\r\n","train_x_px = np.array(train_x_px)\r\n","\r\n","\r\n","# get low resolution images for the validation set\r\n","val_x_px = []\r\n","\r\n","for i in range(val_x.shape[0]):\r\n","  temp = pixalate_image(val_x[i,:,:,:])\r\n","  val_x_px.append(temp)\r\n","\r\n","val_x_px = np.array(val_x_px)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:05.114613Z","iopub.execute_input":"2021-08-03T06:17:05.115075Z","iopub.status.idle":"2021-08-03T06:17:06.464851Z","shell.execute_reply.started":"2021-08-03T06:17:05.115027Z","shell.execute_reply":"2021-08-03T06:17:06.463694Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["Input_img = Input(shape=(76, 76, 3))  \r\n","    \r\n","#encoding architecture\r\n","x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(Input_img)\r\n","x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x1)\r\n","x2 = MaxPool2D( (2, 2))(x2)\r\n","encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\r\n","\r\n","# decoding architecture\r\n","x3 = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\r\n","x3 = UpSampling2D((2, 2))(x3)\r\n","x2 = Conv2D(128, (3, 3), activation='relu', padding='same')(x3)\r\n","x1 = Conv2D(256, (3, 3), activation='relu', padding='same')(x2)\r\n","decoded = Conv2D(3, (3, 3), padding='same')(x1)\r\n","\r\n","autoencoder = Model(Input_img, decoded)\r\n","autoencoder.compile(optimizer='adam', loss='mse')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:21:17.777842Z","iopub.execute_input":"2021-08-03T06:21:17.778429Z","iopub.status.idle":"2021-08-03T06:21:17.883139Z","shell.execute_reply.started":"2021-08-03T06:21:17.778343Z","shell.execute_reply":"2021-08-03T06:21:17.881975Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["autoencoder.summary()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:21:20.938668Z","iopub.execute_input":"2021-08-03T06:21:20.939062Z","iopub.status.idle":"2021-08-03T06:21:20.955595Z","shell.execute_reply.started":"2021-08-03T06:21:20.939024Z","shell.execute_reply":"2021-08-03T06:21:20.952713Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["early_stopper = EarlyStopping(monitor = 'val_loss', min_delta = 0.0001, patience = 4, verbose = 1, mode = 'auto')\r\n","\r\n","a_e = autoencoder.fit(train_x_px, train_x,\r\n","            epochs = 50,\r\n","            batch_size = 256,\r\n","            shuffle = True,\r\n","            validation_data = (val_x_px, val_x),\r\n","            callbacks = [early_stopper])"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:09.366081Z","iopub.execute_input":"2021-08-03T06:17:09.366525Z","iopub.status.idle":"2021-08-03T06:17:11.49342Z","shell.execute_reply.started":"2021-08-03T06:17:09.366479Z","shell.execute_reply":"2021-08-03T06:17:11.490693Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["predictions = autoencoder.predict(val_x_px)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:11.49504Z","iopub.status.idle":"2021-08-03T06:17:11.495582Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["n = 5\r\n","plt.figure(figsize = (20, 10))\r\n","\r\n","for i in range(n):\r\n","  ax = plt.subplot(2, n, i+1)\r\n","  plt.imshow(val_x_px[i+20])\r\n","  ax.get_xaxis().set_visible(False)\r\n","  ax.get_yaxis().set_visible(False)\r\n","\r\n","  ax = plt.subplot(2, n, i+1+n)\r\n","  plt.imshow(predictions[i+20])\r\n","  ax.get_xaxis().set_visible(False)\r\n","  ax.get_yaxis().set_visible(False)\r\n","\r\n","plt.show()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:11.496827Z","iopub.status.idle":"2021-08-03T06:17:11.497822Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","\r\n","autoencoder.save('autoencoder.h5')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:17:11.499395Z","iopub.status.idle":"2021-08-03T06:17:11.500249Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["root_dir = '../input/road-sign-recognition/AIJ_2gisPUBLISH/AIJ_2gis/train_images/'\r\n","sign_images = os.listdir(root_dir)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# img = image.load_img(root_dir+sign_images[0], target_size=(80, 80))\r\n","img = image.load_img(root_dir+sign_images[0], target_size=(80, 80, 3))\r\n","img = image.img_to_array(img)\r\n","img = img/255.0"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["result = autoencoder.predict(img[None])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["plt.rcParams[\"axes.grid\"] = False\r\n","plt.subplot(1,2,1)\r\n","plt.title(\"Original\")\r\n","plt.imshow(img)\r\n","\r\n","plt.subplot(1,2,2)\r\n","plt.title(\"Encoded\")\r\n","plt.imshow(result[0])\r\n","\r\n","plt.show()"],"outputs":[],"metadata":{"trusted":true}}]}